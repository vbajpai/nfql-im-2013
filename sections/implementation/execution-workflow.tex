A custom C library has been written to directly read/write data stored in
\texttt{flow-tools} format. The library sequentially reads the flow-records
into memory to support random access required for relative filtering. Each
flow-record is stored in a \texttt{char} array and the offsets to each field
are stored in separate \texttt{structs} as shown in listing
\ref{lst:c-lib-struct}. The array of such records are indexed allowing fast
retrieval in $O(1)$ time.

\lstset{caption=Trace Data Struct,
				tabsize=2, language=C, numbers=left,stepnumber=1,
        basicstyle=\tiny\ttfamily, numberstyle=\ttfamily\color{gray},
        keywordstyle=\color{blue}, xleftmargin=15pt,
        rulesepcolor=\color{black}, label=lst:c-lib-struct,
        aboveskip=10pt, captionpos=b}
\begin{lstlisting}
struct ft_data {
  int                                         fd;
  struct ftio                                 io;
  struct fts3rec_offsets                      offsets;
  struct ftver                                version;
  u_int64_t                                   xfield;
  int                                         rec_size;
  char**                                      recordset;
  size_t                                      num_records;
};
\end{lstlisting}

In order to be able to make comparisons on the field offsets of a term, the
comparator needs to know the type of the comparison and the length of the
field offset. This information is parsed by execution engine once the query is
read and is therefore not available at compile time.  In order to subvert the
need to define complex branching statements, a dedicated comparator is defined
for every possible field length and comparison operation. A Python script
generates C source code for these comparators at compile time conforming to
the structure shown in listing \ref{lst:filter-struct}. This allows the term
definitions to make runtime calls using a function name derived from the
combination of operation type and field length.

\lstset{caption=Filter Term Struct,
				tabsize=2, language=C, numbers=left,stepnumber=1,
        basicstyle=\tiny\ttfamily, numberstyle=\ttfamily\color{gray},
        keywordstyle=\color{blue}, xleftmargin=15pt,
        rulesepcolor=\color{black}, label=lst:filter-struct,
        aboveskip=10pt, captionpos=b}
\begin{lstlisting}
struct filter_term {
  size_t                                      field_offset;
  uint64_t                                    value;
  uint64_t                                    delta;
  struct filter_op*                           op;
  bool (*func)(
               const char* const              record,
               size_t                         field_offset,
               uint64_t                       value,
               uint64_t                       delta
              );
};
\end{lstlisting}

\subsubsection{Splitter} \ac{NFQL} uses identifiers to reference a flow record
in the \texttt{char} array. This eliminated the need to copy all the
flow-records when moving ahead in the pipeline. As a result, there is no
dedicated splitter stage in the execution engine. Each branch references the
flow records from a common memory location. This helps keep the memory costs
at a minimum when multiple branches are involved.

\subsubsection{Filter}
\begin{figure}[h!]
  \begin{center}
    \includegraphics* [width=0.9\linewidth]{filter-fv1-fv2}
    \caption{Filter Stage: Flowy 2.0 vs NFQL}
    \label{fig:fv1-fv2-filter}
  \end{center}
\end{figure}

The execution engine, as defined by the flow query language must read all the
flow records of a supplied trace into memory before starting the processing
pipeline.  Since, the filter stage uses the supplied set of absolute rules to
make a decision on whether or not to keep a flow record; it has to pass
through the whole in-memory recordset \emph{again} to produce the filter
results. This technique involves multiple linear runs on the trace and
therefore slows down when the ratio of number of filtered records to the total
number of flow-records is high. We optimized this behavior in \ac{NFQL} by
merging the filter stage with in-memory read of the trace. This means, a
decision on whether or not to make room for a record in memory and eventually
hold a pointer for it in filter results is done upfront as soon as the record
is read from the trace. In addition, if a request to write the filter stage
results to a flow-tools file has been made, the writes are also made as soon
the filter stage decision is available, thereby allowing
reading-filtering-writing to happen in $O(n)$ time, where $n$ is the number of
records in the trace. We used the publicly available Trace 7 from the
SimpleWeb \cite{simpleweb} to compare the performance of \ac{NFQL} against the
one defined by the flow query language as shown in Fig.
\ref{fig:fv1-fv2-filter}. The filter stage implementation with these
optimizations runs 10 times faster and is more pronounced on higher ratios.

\begin{figure}[ht!]
  \begin{center}
    \includegraphics*[width=0.9\linewidth]{grouper-fv2-bsearch-fv2}
    \caption{Grouper Stage: NFQL (Generic) vs NFQL (Specific)}
    \label{fig:fv1-fv2-grouper}
  \end{center}
\end{figure}

\subsubsection{Grouper}

In order to be able to make relative comparisons on field offsets, a simple
approach is to linearly walk through each filtered record against the filtered
recordset leading to a complexity of $O(n^2)$, where $n$ is the number of
filtered records. A smarter approach is to put the copy in a hash table and
then try to map each pointer while walking down the filtered recordset once,
leading to a complexity of $O(n)$. The hash table approach however, will only
work on equality comparisons. A better approach, as implemented in \ac{NFQL}
is to sort the filtered recordset on the field offsets of all the requested
grouping terms of a clause. This helps the execution engine perform a nested
binary search to reduce the linear pass to a fairly small filtered recordset.
This helps the grouper perform faster search lookups to find records that must
group together in $O(n*lg(k))$ time with a preprocessing step taking
$O(p*n*lg(n))$ in the average case, where $n$ is the number of filtered
records, $p$ is the number of grouping terms in a clause and $k$ is the number
of unique filtered records. The grouping approach has further been optimized
when the filtered records are grouped for equality. In such a scenario, the
need to search for unique records and a  subsequent binary search goes away.
The groups can now be formed in $O(n)$ time with the same preprocessing step
taking $O(p*n*lg(n))$.  The performance evaluation of the grouper handling
this special case against when handling generic cases is shown in Fig.
\ref{fig:fv1-fv2-grouper}.

The resultant group records are a conglomeration of multiple flow records with
some common characteristics. Some of the non-common characteristics can also
be aggregated into a single value using group aggregations as defined in the
query. Such an aggregated group record is again mapped to a NetFlow $v5$
record template. This allows the aggregated group records to be written to a
file as a representative of all its members.

\subsubsection{Group Filter} The groupfilter stage is used to filter the
groups based on some absolute rules defined in a \ac{DNF} expression. The
\texttt{struct} term holds information about the flow record offset, the value
being compared to and the operator which maps to a unique \texttt{enum} value.
This enum value is used to map the operation to a specific group-filter
function.

\subsubsection{Merger}

The merger is used to relate groups from different branches according to a
merging criterion. The implementation is not trivial since the number of
branches that need to be spawned is read from the query and is not known until
runtime. As a result, an iterator that can provide all possible permutations
of $m-$tuple (where $m$ is the number of branches) group record $ID$s was
implemented. The result of the iterator is then be used to make a match.

The merger as formulated in the flow query language needs to match each group
record from one branch with every other record of each branch. This leads to a
complexity of $O(g^m)$ where $g$ is the number of filtered group records and
$m$ is the number of branches. The possible number of tries when matching
group records, however, can be reduced by sorting the group records on the
field offsets used for a match. \ac{NFQL} optimizes the merger to skip over
iterator permutations when a state of a current field offset value may not
allow any further match beyond the index in the current branch.  For such an
optimization to work, the filtered group records must be sorted in the order
of field offsets specified in the merger clause.  Specifying the filtered
group records in any other order may lead to undefined behavior. This means,
that if the same field offsets were used in the grouper stage, the terms in
the group clause can be rearranged by the query designer to align with the
order of terms in the merger clause.

The flow query language also bases the merger matches on the notion of matched
tuples. This means that a filtered group record can be written to a file
multiple times if it is part of multiple matched tuples. This situation
worsens when different branches have similar filtered groups records. Since,
the function of the merger is to find a match of groups records across
branches based on a predefined condition, all the group records across
branches that satisfy the condition can be clubbed into one collection instead
of separate tuples. All the group records within a collection can then be
written to the file. This eliminates the inherent redundancy and significantly
improves the merger performance.

\subsubsection{Ungrouper} The approach of clubbing the merged group records into
a collection incurs a reimplementation of the ungrouper. The ungrouper, as a
result accepts a collection of matched filtered group records as input. It
then iterates over each collection to unfold it groups and write their flow
record members to files.

